% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_machine_learning.R
\name{sits_lightgbm}
\alias{sits_lightgbm}
\title{Train models using LightGBM algorithm}
\usage{
sits_lightgbm(
  samples = NULL,
  boosting_type = "gbdt",
  num_iterations = 100,
  max_depth = 6,
  min_samples_leaf = 10,
  learning_rate = 0.1,
  n_iter_no_change = 10,
  validation_split = 0.2,
  record = TRUE,
  ...
)
}
\arguments{
\item{samples}{Time series with the training samples.}

\item{boosting_type}{Type of boosting algorithm
(options: "gbdt", "rf", "dart", "goss").}

\item{num_iterations}{Number of iterations.}

\item{max_depth}{Limit the max depth for tree model.}

\item{min_samples_leaf}{Min size of data in one leaf
(can be used to deal with over-fitting).}

\item{learning_rate}{Learning rate of the algorithm}

\item{n_iter_no_change}{Number of iterations to stop training
when validation metrics don't improve.}

\item{validation_split}{Fraction of training data
to be used as validation data.}

\item{record}{Record iteration message?}

\item{...}{Additional parameters for
\code{lightgbm::lgb.train} function.}
}
\description{
This function uses the LightGBM algorithm for model training.
LightGBM is a fast, distributed, high performance gradient boosting
framework based on decision trees.
}
\note{
Please refer to the sits documentation available in
<https://e-sensing.github.io/sitsbook/> for detailed examples.
}
\references{
Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen,
Weidong Ma, Qiwei Ye, Tie-Yan Liu.
"LightGBM: A Highly Efficient Gradient Boosting Decision Tree".
Advances in Neural Information Processing Systems 30 (NIPS 2017), pp. 3149-3157.
}
\author{
Rolf Simoes, \email{rolf.simoes@inpe.br}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Alber Sanchez, \email{alber.ipia@inpe.br}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_machine_learning.R
\name{sits_lightgbm}
\alias{sits_lightgbm}
\title{Train models using lightGBM algorithm}
\usage{
sits_lightgbm(
  data = NULL,
  boosting_type = "gbdt",
  num_iterations = 100,
  max_depth = 6,
  min_samples_leaf = 10,
  learning_rate = 0.1,
  n_iter_no_change = 0,
  n_folds = 5,
  record = TRUE,
  ...
)
}
\arguments{
\item{data}{time series with the training samples.}

\item{boosting_type}{type of boosting algorithm
(options: "gbdt", "rf", "dart", "goss")}

\item{num_iterations}{number of iterations}

\item{max_depth}{limit the max depth for tree model}

\item{min_samples_leaf}{minimal number of data in one leaf
(can be used to deal with over-fitting)}

\item{learning_rate}{learning rate of the algorithm}

\item{n_iter_no_change}{number of iterations to stop training
when validation metrics don't improve}

\item{n_folds}{number of folds for cross-validation.}

\item{record}{record iteration message?}
}
\description{
This function uses the lightGBM algorithm for model training.
LightGBM is a fast, distributed, high performance gradient boosting
framework based on decision trees.
}
\references{
Guolin Ke, Qi Meng, Thomas Finley, Taifeng Wang, Wei Chen,
Weidong Ma, Qiwei Ye, Tie-Yan Liu.
"LightGBM: A Highly Efficient Gradient Boosting Decision Tree".
Advances in Neural Information Processing Systems 30 (NIPS 2017), pp. 3149-3157.
}
\author{
Rolf Simoes, \email{rolf.simoes@inpe.br}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Alber Sanchez, \email{alber.ipia@inpe.br}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_PSE-LTAE.R
\name{sits_PSE-LTAE}
\alias{sits_PSE-LTAE}
\alias{sits_LTAE}
\title{Train a model using  Pixel-Set Encoders and Temporal Self-Attention}
\usage{
sits_LTAE(
  samples = NULL,
  blocks = c(64, 128, 128),
  kernels = c(7, 5, 3),
  activation = "relu",
  optimizer = torch::optim_adam,
  learning_rate = 0.001,
  epochs = 300,
  batch_size = 64,
  validation_split = 0.2,
  verbose = FALSE
)
}
\arguments{
\item{samples}{Time series with the training samples.}

\item{blocks}{Number of 1D convolutional filters for
each block of three layers.}

\item{kernels}{Size of the 1D convolutional kernels
for each layer of each block.}

\item{activation}{Activation function for 1D convolution.
Valid values: {'relu', 'elu', 'selu', 'sigmoid'}.}

\item{optimizer}{Function with a pointer to the optimizer function
(default is optimization_adam()).
Options: optimizer_adadelta(), optimizer_adagrad(),
optimizer_adam(), optimizer_adamax(),
optimizer_nadam(), optimizer_rmsprop(),
optimizer_sgd().}

\item{epochs}{Number of iterations to train the model.}

\item{batch_size}{Number of samples per gradient update.}

\item{validation_split}{Number between 0 and 1. Fraction of training data
to be used as validation data.
The model will set apart this fraction of the
training data, will not train on it,
and will evaluate the loss and any model metrics
on this data at the end of each epoch.
The validation data is selected from the last
samples in the x and y data provided,
before shuffling.}

\item{verbose}{Verbosity mode (0 = silent, 1 = progress bar,
2 = one line per epoch).}
}
\value{
A fitted model to be passed to \code{\link[sits]{sits_classify}}
}
\description{
Implementation of the PSE (Pixel Set Encoding) +
Light Temporal Attention Encoder (L-TAE)
for satellite image time series classification.

This function is based on the paper by Vivien Garnot referenced below
and code available on github at
https://github.com/VSainteuf/lightweight-temporal-attention-pytorch/blob/master/models/ltae.py.
If you use this method, please cite the original LTAE paper.

We also used the code made available by Maja Schneider in her work with
Marco Körner referenced below and available at
https://github.com/maja601/RC2020-psetae.
}
\examples{
\dontrun{
# Retrieve the set of samples for the Mato Grosso (provided by EMBRAPA)

# Build a machine learning model based on deep learning
rn_model <- sits_train(samples_modis_4bands, sits_LTAE(epochs = 75))
# Plot the model
plot(rn_model)

# get a point and classify the point with the ml_model
point <- sits_select(point_mt_6bands,
    bands = c("NDVI", "EVI", "NIR", "MIR")
)
class <- sits_classify(point, rn_model)
plot(class, bands = c("NDVI", "EVI"))
}
}
\references{
Vivien Sainte Fare Garnot and Loic Landrieu,
"Lightweight Temporal Self-Attention
for Classifying Satellite Image Time Series", https://arxiv.org/abs/2007.00586

Schneider, Maja; Körner, Marco,
"[Re] Satellite Image Time Series Classification
with Pixel-Set Encoders and Temporal Self-Attention." ReScience C 7 (2), 2021.
}
\author{
Charlotte Pelletier, \email{charlotte.pelletier@univ-ubs.fr}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}
}

% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/sits_LTAE.R
\name{sits_LTAE}
\alias{sits_LTAE}
\title{Train a model using Lightweight Temporal Self-Attention}
\usage{
sits_LTAE(
  samples = NULL,
  cnn_layers = c(64, 64, 64),
  cnn_kernels = c(5, 5, 5),
  cnn_activation = "relu",
  cnn_L2_rate = 1e-06,
  cnn_dropout_rates = c(0.5, 0.5, 0.5),
  mlp_layers = c(256),
  mlp_activation = "relu",
  mlp_dropout_rates = c(0.5),
  optimizer = keras::optimizer_adam(lr = 0.001),
  epochs = 150,
  batch_size = 128,
  validation_split = 0.2,
  verbose = 0
)
}
\arguments{
\item{samples}{Time series with the training samples.}

\item{mlp_layers}{Number of nodes in the multi-layer-perceptron.}

\item{mlp_activation}{Names of 2D activation functions for the MLP.
Valid values: {'relu', 'elu', 'selu', 'sigmoid'}.}

\item{mlp_dropout_rates}{Dropout rates (0,1) for each layer in the MLP.}

\item{optimizer}{Function with a pointer to the optimizer function
(default is optimization_adam()).
Options: optimizer_adadelta(), optimizer_adagrad(),
optimizer_adam(), optimizer_adamax(),
optimizer_nadam(), optimizer_rmsprop(),
optimizer_sgd().}

\item{epochs}{Number of iterations to train the model.}

\item{batch_size}{Number of samples per gradient update.}

\item{validation_split}{Number between 0 and 1. Fraction of training data
to be used as validation data.
The model will set apart this fraction of the
training data, will not train on it,
and will evaluate the loss and any model metrics
on this data at the end of each epoch.
The validation data is selected from the last
samples in the x and y data provided,
before shuffling.}

\item{verbose}{Verbosity mode (0 = silent, 1 = progress bar,
2 = one line per epoch).}

\item{in_channels}{Number of channels of the input embeddings}

\item{n_head}{Number of attention heads}

\item{d_k}{Dimension of the key and query vectors}

\item{n_neurons}{Defines the dimensions of the successive feature spaces of the MLP that processes
the concatenated outputs of the attention heads}

\item{dropout}{dropout}

\item{T}{Period to use for the positional encodin}

\item{len_max_seq}{Maximum sequence length, used to pre-compute the positional encoding table}

\item{positions}{List of temporal positions to use instead of position in the sequence}

\item{return_att}{If true, the module returns the attention masks along with the embeddings (default False)}
}
\value{
A fitted model to be passed to \code{\link[sits]{sits_classify}}
}
\description{
Implementation of the Light Temporal Attention Encoder (L-TAE)
for satellite image time series classification.

This function is based on the paper by Vivien Garnot referenced below
and code available on github (https://github.com/VSainteuf/pytorch-psetae).
If you use this method, please cite the original LTAE paper.
}
\examples{
\dontrun{
# Retrieve the set of samples for the Mato Grosso (provided by EMBRAPA)

# Build a machine learning model
ltae_model <- sits_train(samples_modis_4bands, sits_LTAE(epochs = 75))
# Plot the model
plot(ltae_model)

# get a point and classify the point with the ml_model
point <- sits_select(point_mt_6bands, bands = c("NDVI", "EVI", "NIR", "MIR"))
class <- sits_classify(point, ltae_model)

plot(class, bands = c("NDVI", "EVI"))
}
}
\references{
Vivien Sainte Fare Garnot and Loic Landrieu,
"Lightweight Temporal Self-Attention
for Classifying Satellite Image Time Series", https://arxiv.org/abs/2007.00586
}
\author{
Charlotte Pelletier, \email{charlotte.pelletier@univ-ubs.fr}

Gilberto Camara, \email{gilberto.camara@inpe.br}

Rolf Simoes, \email{rolf.simoes@inpe.br}
}
